mutate(mgH_usL = map2(mgH_usL1, mgH_usL2, ~ list(.x, .y))) %>%
select(-mgL_usH1, -mgL_usH2, -mgL_usL1, -mgL_usL2, -mgH_usH1, -mgH_usH2, -mgH_usL1, -mgH_usL2 )  # Remove the original keys
# Convert the modified dataframe back to JSON
output_json <- toJSON(df_combined, pretty = TRUE, auto_unbox = TRUE)
# Print the resulting JSON
# cat(output_json)
# write(output_json, file = "output/full-12-2026.json")
write(output_json, file = paste("output/", gsub("\\.", "", dsL), "-", gsub("\\.", "", dsH), "-full.json", sep = ""))
final <- getPairs(dsL, dsH)  %>% drop_na()
# Lower and Higher thresholds for deltaS
dsL = 0.1; dsH = 0.7
final <- getPairs(dsL, dsH)  %>% drop_na()
unique(final$concept1); unique(final$concept2);
# find which columns of the dataframe only have NAs
names(final)[sapply(final, function(x) sum(is.na(x)) == length(x))]
final <- final %>% filter(!is.na(mgH_usL1), !is.na(mgH_usL2))
# unique combinations of two columns concept1 and concept2
final %>% distinct(concept1, concept2)
unique(final$concept1)
unique(final$concept2)
final %>% group_by(concept1, concept2) %>% summarize(freq = n())
# Lower and Higher thresholds for deltaS
dsL = 0.1; dsH = 0.65
final <- getPairs(dsL, dsH)  %>% drop_na()
unique(final$concept1); unique(final$concept2);
# find which columns of the dataframe only have NAs
names(final)[sapply(final, function(x) sum(is.na(x)) == length(x))]
final <- final %>% filter(!is.na(mgH_usL1), !is.na(mgH_usL2))
# unique combinations of two columns concept1 and concept2
final %>% distinct(concept1, concept2)
final %>% group_by(concept1, concept2) %>% summarize(freq = n())
# Lower and Higher thresholds for deltaS
dsL = 0.05; dsH = 0.65
final <- getPairs(dsL, dsH)  %>% drop_na()
unique(final$concept1); unique(final$concept2);
# find which columns of the dataframe only have NAs
names(final)[sapply(final, function(x) sum(is.na(x)) == length(x))]
final <- final %>% filter(!is.na(mgH_usL1), !is.na(mgH_usL2))
# find which columns of the dataframe only have NAs
names(final)[sapply(final, function(x) sum(is.na(x)) == length(x))]
final <- final %>% filter(!is.na(mgH_usL1), !is.na(mgH_usL2))
# unique combinations of two columns concept1 and concept2
final %>% distinct(concept1, concept2)
final %>% group_by(concept1, concept2) %>% summarize(freq = n())
## Adding color code to Final dataset
bcp37 <- read_csv("utils/color_values_bcp37.csv")# %>% select('name', 'color', 'hex')
write_csv(final, paste("output/", gsub("\\.", "", dsL), "-", gsub("\\.", "", dsH), "-final.csv", sep = ""))
library(jsonlite)
## !!! NOTE The FILTER
df <- final # %>% filter(mgL_usH1 == "WH", mgL_usH2 == "DP", mgH_usH1=="DG", mgH_usH2 == "BK")
json_list <- list()
for (i in 1:nrow(df)) {
# Extract values for the current row
row_data <- df[i, ]
# Define the JSON structure for the current row
json_data <- list(
concept1 = row_data$concept1,
concept2 = row_data$concept2,
mgL_usH = list(row_data$mgL_usH1, row_data$mgL_usH2),
mgH_usH = list(row_data$mgH_usH1, row_data$mgH_usH2),
mgL_usL = list(row_data$mgL_usL1, row_data$mgL_usL2),
mgH_usL = list(row_data$mgH_usL1, row_data$mgH_usL2))
json_list[[i]] <- json_data
}
# Convert the entire list to JSON and write it to a single file
json_string <- toJSON(json_list, pretty = TRUE, auto_unbox = TRUE)
# write(json_string, file = "output/final-12-2026.json")
write(json_string, file = paste("output/", gsub("\\.", "", dsL), "-", gsub("\\.", "", dsH), "-final.json", sep = ""))
# Lower and Higher thresholds for deltaS
dsL = 0.1; dsH = 0.7
final <- getPairs(dsL, dsH)  %>% drop_na()
unique(final$concept1); unique(final$concept2);
# find which columns of the dataframe only have NAs
names(final)[sapply(final, function(x) sum(is.na(x)) == length(x))]
final <- final %>% filter(!is.na(mgH_usL1), !is.na(mgH_usL2))
# unique combinations of two columns concept1 and concept2
final %>% distinct(concept1, concept2)
final %>% group_by(concept1, concept2) %>% summarize(freq = n())
## Adding color code to Final dataset
bcp37 <- read_csv("utils/color_values_bcp37.csv")# %>% select('name', 'color', 'hex')
## Adding color code to Final dataset
bcp37 <- read_csv("utils/color_values_bcp37.csv")# %>% select('name', 'color', 'hex')
```{r cross-cultural analysis}
write_csv(final, paste("output/", gsub("\\.", "", dsL), "-", gsub("\\.", "", dsH), "-final.csv", sep = ""))
write_csv(final, paste("output/", gsub("\\.", "", dsL), "-", gsub("\\.", "", dsH), "-final.csv", sep = ""))
```{r more analysis}
library(jsonlite)
## !!! NOTE The FILTER
df <- final %>% filter(mgL_usH1 == "WH", mgL_usH2 == "DP", mgH_usH1=="DG", mgH_usH2 == "BK")
## !!! NOTE The FILTER
df <- final # %>% filter(mgL_usH1 == "WH", mgL_usH2 == "DP", mgH_usH1=="DG", mgH_usH2 == "BK")
json_list <- list()
for (i in 1:nrow(df)) {
# Extract values for the current row
row_data <- df[i, ]
# Define the JSON structure for the current row
json_data <- list(
concept1 = row_data$concept1,
concept2 = row_data$concept2,
mgL_usH = list(row_data$mgL_usH1, row_data$mgL_usH2),
mgH_usH = list(row_data$mgH_usH1, row_data$mgH_usH2),
mgL_usL = list(row_data$mgL_usL1, row_data$mgL_usL2),
mgH_usL = list(row_data$mgH_usL1, row_data$mgH_usL2))
json_list[[i]] <- json_data
}
# Convert the entire list to JSON and write it to a single file
json_string <- toJSON(json_list, pretty = TRUE, auto_unbox = TRUE)
# write(json_string, file = "output/final-12-2026.json")
write(json_string, file = paste("output/", gsub("\\.", "", dsL), "-", gsub("\\.", "", dsH), "-final.json", sep = ""))
# write(json_string, file = "output/final-12-2026.json")
write(json_string, file = paste("output/", gsub("\\.", "", dsL), "-", gsub("\\.", "", dsH), "-final.json", sep = ""))
df2 <- bcp37
# Function to create JSON-like entry
create_json_entry <- function(code) {
entry <- df2 %>% filter(color == code)
if (nrow(entry) > 0) {
return(list(color = code, hex = entry$hex, L = entry$L, a = entry$a, b = entry$b))
# return(list(color = code, hex = entry$hex, L = entry$L))
} else {
return(NULL)  # Return NULL if the color code doesn't exist in df2
}
}
# Replace color codes with JSON entries
df_replaced <- df %>%
mutate(across(starts_with("mg"), ~map(.x, create_json_entry)))
# Replace color codes with JSON entries
df_replaced <- df %>%
mutate(across(starts_with("mg"), ~map(.x, create_json_entry)))
View(df)
# Convert the transformed dataframe back to JSON
output_json <- toJSON(df_replaced, pretty = TRUE, auto_unbox = TRUE)
df_combined <- df_replaced %>%
mutate(mgL_usH = map2(mgL_usH1, mgL_usH2, ~ list(.x, .y))) %>%
mutate(mgL_usL = map2(mgL_usL1, mgL_usL2, ~ list(.x, .y))) %>%
mutate(mgH_usH = map2(mgH_usH1, mgH_usH2, ~ list(.x, .y))) %>%
mutate(mgH_usL = map2(mgH_usL1, mgH_usL2, ~ list(.x, .y))) %>%
select(-mgL_usH1, -mgL_usH2, -mgL_usL1, -mgL_usL2, -mgH_usH1, -mgH_usH2, -mgH_usL1, -mgH_usL2 )  # Remove the original keys
# Convert the modified dataframe back to JSON
output_json <- toJSON(df_combined, pretty = TRUE, auto_unbox = TRUE)
# Print the resulting JSON
# cat(output_json)
# write(output_json, file = "output/full-12-2026.json")
write(output_json, file = paste("output/", gsub("\\.", "", dsL), "-", gsub("\\.", "", dsH), "-full.json", sep = ""))
# Print the resulting JSON
# cat(output_json)
# write(output_json, file = "output/full-12-2026.json")
write(output_json, file = paste("output/", gsub("\\.", "", dsL), "-", gsub("\\.", "", dsH), "-full.json", sep = ""))
concept_pairs <- as.data.frame(t(combn(unique(usdf$concept), 2))) %>% rename(concept1 = V1, concept2 = V2)
color_pairs <- as.data.frame(t(combn(unique(mgdf$color), 2))) %>% rename(color1 = V1, color2 = V2)
# Aggregated data (x = average rating for each color of each concept)
usdf_agg <- usdf %>% group_by(concept, color) %>% summarise(xbar = mean(rating), sd_sample = sd(rating), .groups = 'drop')
a_us <- coef(getFitSd(usdf_agg)) # alpha a_us = 1.384426
# Plotting the data points, and fitted curve
plot(usdf_agg$xbar, usdf_agg$sd_sample, main = "Fit for model s = a * xbar * (1 - xbar)",
xlab = "Mean (xbar)", ylab = "Standard Deviation (s)", pch = 16)
curve(coef(getFitSd(usdf_agg)) * x * (1 - x), add = TRUE, col = "orange", lwd = 2)
a_us2 <- coef(getFitSd2(usdf_agg)) # alpha a = 0.37, beta b = 0.32
plot(usdf_agg$xbar, usdf_agg$sd_sample, main = "Fit for model s = a * xbar^b",
xlab = "Mean (xbar)", ylab = "Standard Deviation (s)", pch = 16)
curve(coef(getFitSd2(usdf_agg))[1] * x^coef(getFitSd2(usdf_agg))[2], add = TRUE, col = "red", lwd = 2)
# xUs <- getXvalues(usdf_agg, concept_pairs, color_pairs, a_us) %>% mutate(deltaX = (xbar1 + xbar4) - (xbar2 + xbar3))
xUs2 <- getXvalues_opt(usdf_agg, concept_pairs, color_pairs, a_us) %>% mutate(deltaX = (xbar1 + xbar4) - (xbar2 + xbar3))
View(xUs2)
View(usdf_w)
View(usdf_w)
View(usdf_agg)
View(usdf_w)
View(usdf_agg)
View(row_data)
View(deltaS_mg)
View(deltaS_mg)
View(deltaS_us)
View(deltaS_us)
View(bcp37)
View(a)
View(bcp37)
View(bcp37hex)
View(color_pairs)
View(dsmg)
View(deltaS_mg)
View(mgdf_w)
View(scatterDf)
View(tmp)
View(usdem)
View(xMg2)
## Association weight MDG
mgdf_w$con = factor(mgdf_w$concept, levels=conceptListEn3) # to order the facet strips
p1 <- plotWeight_Err(mgdf_w, "Mean weight of assoc, lib: BCP37, MDG"); p1
## Association weight USA
usdf_w$con = factor(usdf_w$concept, levels=conceptListEn3) # to order the facet strips
View(dsus)
dsusX <- dsus %>% filter(concept1 == "sick", concept2 == "tree")
unique(dsusX$color1)
unique(dsusX$color2)
sort(unique(dsusX$color2))
sort(unique(dsusX$color1))
dsusX <- dsus %>% filter(concept1 == "sick", concept2 == "tree", color1=="LY")
View(dsusX)
View(xUs2)
View(dsmg)
dsmgX <- dsmg %>% filter(concept1 == "angry", concept2 == "banana")
View(dsmgX)
View(xMg2)
View(xUs2)
View(xUs2 %>% filter(concept1 == "angry", concept2=="banana"))
View(xUs2 %>% filter(concept1 == "angry", concept2=="banana", color1 == "A1"))
View(dsmg)
View(mgdf)
View(mgdf %>% filter(concept == angry))
View(mgdf %>% filter(concept == "angry"))
View(mgdf %>% filter(concept == "angry") %>% select(concept, rating))
View(mgdf_w %>% filter(concept == "angry") )
View(mgdf_w %>% filter(concept == "justice") )
View(mgdf_w %>% filter(concept == "safety") )
# Unique pairs of concepts and pairs of colors without repetition
# ie. {red, yellow} == {yellow, red}
concept_pairs <- as.data.frame(t(combn(unique(dfus$concept), 2))) %>% rename(concept1 = V1, concept2 = V2)
# Unique pairs of concepts and pairs of colors without repetition
# ie. {red, yellow} == {yellow, red}
concept_pairs <- as.data.frame(t(combn(unique(dfus$concept), 2))) %>% rename(concept1 = V1, concept2 = V2)
concept_pairs <- as.data.frame(t(combn(unique(usdf$concept), 2))) %>% rename(concept1 = V1, concept2 = V2)
concept_pairs <- as.data.frame(t(combn(unique(usdf$concept), 2))) %>% rename(concept1 = V1, concept2 = V2)
View(concept_pairs)
View(concept_pairs)
color_pairs <- as.data.frame(t(combn(unique(mgdf$color), 2))) %>% rename(color1 = V1, color2 = V2)
View(usdf_w)
View(xUs2)
filter(xUs2, deltaX == 0,0554)
filter(xUs2, deltaX == 0.0554)
View(xUs2)
View(xMg2)
View(xUs2)
View(xUs2)
View(dsmg)
View(usdf_w)
View(xUs2)
View(filter(xUs2, concep1 == "angry"))
View(filter(xUs2, concept1 == "angry"))
View(filter(xUs2, concept1 == "angry", color1 == "A1"))
View(filter(xUs2, concept1 == "angry", color1 == "A2"))
xx <- (filter(xUs2, concept1 == "angry", color1 == "A2"))
xx <- (filter(xUs2, concept1 == "happy", color1 == "A1"))
xx <- (filter(xUs2, concept1 == "happy", color1 == "A1")); View(xx)
xx <- (filter(xUs2, concept1 == "mango", color1 == "BK")); View(xx)
View(usdf_w)
xx <- (filter(xUs2, concept1 == "angry", concept2 == "banana")); View(xx)
xx <- (filter(xUs2, concept1 == "angry", concept2 == "banana", color1 == "A1")); View(xx)
View(xx)
View(dsus)
View(dsusX)
View(dsus)
dsusX <- filter(dsus, concept1 == "angry", concept2 == "banana", color1 == "A1")
View(deltaS_mg)
View(deltaS_us)
View(dsusX)
View(deltaS_us %>% filter(concept1 == "angry", concept2 == "banana", color1 == "A1"))
dsusX <- filter(deltaS_us, concept1 == "mango", concept2 == "banana", color1 == "A1")
unique(dsusX$concept2)
dsusX <- filter(deltaS_us, concept1 == "mango")
unique(dsusX$concept2)
dsusX <- filter(deltaS_us, concept1 == "mango", concept2 == "peach")
dsusX <- filter(deltaS_us, concept1 == "mango", concept2 == "peach", color1 == "A1")
View(dsus)
library(readr)
library(dplyr)
library(tidyr)
library(clue)   # solve_LSAP()
# Build mean (xbar) and sigma matrices for a chosen concept set and color set
build_xbar_sigma <- function(summary_df, concepts, colors, sd_scale = 1.4) {
# summary_df = us_sum
df <- summary_df %>%
filter(concept %in% concepts, color %in% colors) %>%
select(concept, color, mean_rating)
# Ensure full grid exists
grid <- expand_grid(concept = concepts, color = colors) %>%
left_join(df, by = c("concept", "color"))
if (any(is.na(grid$mean_rating))) {
missing <- grid %>% filter(is.na(mean_rating))
stop("Missing mean_rating for some concept-color pairs:\n", paste0(missing$concept, " × ", missing$color, collapse = ", "))}
# xbar in [0,1]
xbar <- grid$mean_rating
if (any(xbar < -1e-6 | xbar > 1 + 1e-6)) {stop("mean_rating must be in [0,1]. If your data is 0–100, divide by 100 first.")}
k <- length(concepts)
xbar_mat <- matrix(xbar, nrow = k, ncol = k, byrow = TRUE, dimnames = list(concepts, colors))
sigma_mat <- sd_scale * xbar_mat * (1 - xbar_mat)
list(xbar = xbar_mat, sigma = sigma_mat)
}
# Run Monte Carlo and compute assignment distribution + metrics
semantic_discriminability_k <- function(summary_df, concepts, colors,
n_sims = 5000, sd_scale = 1.4, clamp_01 = TRUE, seed = 1) {
stopifnot(length(concepts) == length(colors))
k <- length(concepts)
mats <- build_xbar_sigma(summary_df, concepts, colors, sd_scale = sd_scale)
xbar <- mats$xbar
sigma <- mats$sigma
set.seed(seed)
# Store assignment keys and confusion counts
## assign_key: the full mapping (assignment) produced on each Monte Carlo simulation.
## assign_key tracks which complete k↔k mapping happened each simulation
assign_key <- character(n_sims)
## conf_counts: counts of how often each concept gets assigned to each color across simulations.
## conf_counts aggregates per-concept assignment frequencies across simulations.
conf_counts <- matrix(0L, nrow = k, ncol = k, dimnames = list(concepts, colors))
xbar_vec  <- as.vector(xbar)
sigma_vec <- as.vector(sigma)
for (s in seq_len(n_sims)) {
# Sample all edges
samp_vec <- rnorm(k * k, mean = xbar_vec, sd = sigma_vec)
samp_mat <- matrix(samp_vec, nrow = k, ncol = k, byrow = TRUE)
# Optionally clamp to [0,1] (useful because Normal can go outside bounds)
if (clamp_01) samp_mat <- pmin(pmax(samp_mat, 0), 1)
# Max-sum assignment: solve_LSAP minimizes cost, so use cost = -score
perm <- as.integer(solve_LSAP(samp_mat, maximum = TRUE))  # perm[i] = assigned column for row i
# Key for this mapping (concept order is fixed)
# Example: "2,5,1,3,4" meaning row1->col2, row2->col5, row3->col1, row4->col3, row5->col4 ...
assign_key[s] <- paste(perm, collapse = ",")
# Update confusion counts
for (i in seq_len(k)) {
conf_counts[i, perm[i]] <- conf_counts[i, perm[i]] + 1L
}
}
# Assignment distribution
tab <- sort(table(assign_key), decreasing = TRUE)
probs <- as.numeric(tab) / n_sims
p_best <- probs[1]
p_second <- if (length(probs) >= 2) probs[2] else 0
margin <- p_best - p_second
# Entropy over assignments (bits)
entropy_bits <- -sum(probs * log2(probs))
# Optional: normalize by log2(k!) (max possible entropy if all permutations equally likely)
log2_kfact <- log2(factorial(k))
entropy_norm <- entropy_bits / log2_kfact  # ~0 (very stable) to ~1 (very ambiguous)
# Decode top assignments into explicit mappings
decode_perm <- function(key) as.integer(strsplit(key, ",", fixed = TRUE)[[1]])
top_df <- tibble(
assignment_key = names(tab),
prob = probs) %>%
mutate(rank = row_number()) %>%
# slice_head(n = min(20, n())) %>%
head(20) %>%
rowwise() %>%
mutate(
perm = list(decode_perm(assignment_key)),
mapping = paste0(concepts, "→", colors[unlist(perm)], collapse = " | ")) %>%
ungroup() %>%
select(rank, prob, mapping, assignment_key)
# Confusion probabilities (concept -> color)
conf_prob <- conf_counts / n_sims
conf_long <- as.data.frame(as.table(conf_prob)) %>%
rename(concept = Var1, color = Var2, prob = Freq) %>%
arrange(concept, desc(prob))
list(
inputs = list(concepts = concepts, colors = colors, n_sims = n_sims,
sd_scale = sd_scale, clamp_01 = clamp_01, seed = seed),
metrics = tibble(
k = k,
n_sims = n_sims,
p_best = p_best,
p_second = p_second,
margin = margin,
entropy_bits = entropy_bits,
entropy_norm = entropy_norm
),
top_assignments = top_df,
confusion = conf_long
)
}
# Read your 0–1 summaries
mg_sum <- read_csv("cg/mg_concept_color_summary.csv", show_col_types = FALSE)
us_sum <- read_csv("cg/us_concept_color_summary.csv", show_col_types = FALSE)
# Choose a palette scenario (k concepts, k colors)
concepts <- c("sick","happy","banana")
colors   <- c("DC","LH","MC")
# Run for each group
mg_res <- semantic_discriminability_k(mg_sum, concepts, colors, n_sims = 10000, seed = 42)
us_res <- semantic_discriminability_k(us_sum, concepts, colors, n_sims = 10000, seed = 42)
# Compare (semantic discriminability gap)
mg_res$metrics
us_res$metrics
gap_entropy_bits <- us_res$metrics$entropy_bits - mg_res$metrics$entropy_bits
gap_pbest        <- us_res$metrics$p_best - mg_res$metrics$p_best
# Inspect the most likely mappings
mg_res$top_assignments
us_res$top_assignments
# Inspect confusion probabilities
mg_res$confusion
us_res$confusion
# Run for each group
mg_res1 <- semantic_discriminability_k(mg_sum, concepts, colors, n_sims = 10000, seed = 42)
us_res1 <- semantic_discriminability_k(us_sum, concepts, colors, n_sims = 10000, seed = 42)
# Compare (semantic discriminability gap)
mg_res1$metrics
us_res1$metrics
gap_entropy_bits <- us_res1$metrics$entropy_bits - mg_res1$metrics$entropy_bits
gap_pbest        <- us_res1$metrics$p_best - mg_res1$metrics$p_best
# Inspect the most likely mappings
mg_res1$top_assignments
us_res1$top_assignments
# Run for each group
mg_res1 <- semantic_discriminability_k(mg_sum, concepts, colors, n_sims = 10000, seed = 40)
# Compare (semantic discriminability gap)
mg_res1$metrics
us_res1$metrics
gap_entropy_bits <- us_res1$metrics$entropy_bits - mg_res1$metrics$entropy_bits
gap_pbest        <- us_res1$metrics$p_best - mg_res1$metrics$p_best
# Inspect the most likely mappings
mg_res1$top_assignments
# Run for each group
mg_res1 <- semantic_discriminability_k(mg_sum, concepts, colors, n_sims = 10000, seed = 4)
us_res1 <- semantic_discriminability_k(us_sum, concepts, colors, n_sims = 10000, seed = 4)
# Compare (semantic discriminability gap)
mg_res1$metrics
us_res1$metrics
gap_entropy_bits <- us_res1$metrics$entropy_bits - mg_res1$metrics$entropy_bits
gap_pbest        <- us_res1$metrics$p_best - mg_res1$metrics$p_best
# Inspect the most likely mappings
mg_res1$top_assignments
us_res1$top_assignments
# Inspect the most likely mappings
mg_res1$top_assignments
# Choose a palette scenario (k concepts, k colors)
concepts <- c("sick","happy","banana")
colors   <- c("BK","LH","MC")
# Run for each group
mg_res1 <- semantic_discriminability_k(mg_sum, concepts, colors, n_sims = 10000, seed = 4)
us_res1 <- semantic_discriminability_k(us_sum, concepts, colors, n_sims = 10000, seed = 4)
# Compare (semantic discriminability gap)
mg_res1$metrics
us_res1$metrics
gap_entropy_bits <- us_res1$metrics$entropy_bits - mg_res1$metrics$entropy_bits
gap_pbest        <- us_res1$metrics$p_best - mg_res1$metrics$p_best
# Inspect the most likely mappings
mg_res1$top_assignments
View(xMg2)
xMg2x <- filter(xMg2, concept1 %in% c('happy'))
View(xMg2x)
xMg2x <- filter(xMg2, concept1 %in% c('happy'), color1 %in% c('BK'))
xMg2x <- filter(xMg2, concept1 %in% c('happy'), color1 %in% c('LH'))
knitr::opts_chunk$set(echo = TRUE)
source(file = './utils/exp1-utils.R')  # loads all necessary packages
source(file = './utils/stimuli.R')
source(file = './utils/exp1-analysis-utils.R')
knitr::opts_chunk$set(echo = TRUE)
source(file = './utils/exp1-utils.R')  # loads all necessary packages
source(file = './utils/stimuli.R')
source(file = './utils/exp1-analysis-utils.R')
dataPath = "data/exp1/csv/2026/"
mgdem = read_csv(paste(dataPath, "mg-dem.csv", sep = ''))
mgdf = read_csv(paste(dataPath, "mg-df.csv", sep = ''))
mgdf_w = read_csv(paste(dataPath, "mg-df-weight.csv", sep = ''))
usdem = read_csv(paste(dataPath, "us-dem.csv", sep = ''))
usdf = read_csv(paste(dataPath, "us-df.csv", sep = ''))
usdf_w = read_csv(paste(dataPath, "us-df-weight.csv", sep = ''))
rm(dataPath)
## Association weight MDG
mgdf_w$con = factor(mgdf_w$concept, levels=conceptListEn3) # to order the facet strips
p1 <- plotWeight_Err(mgdf_w, "Mean weight of assoc, lib: BCP37, MDG"); p1
## Association weight USA
usdf_w$con = factor(usdf_w$concept, levels=conceptListEn3) # to order the facet strips
p2 <- plotWeight_Err(usdf_w, "Mean weight of assoc., lib: BCP37, USA") +
theme(axis.title.y = element_blank(), axis.text.y = element_blank()); p2
p12 <- grid.arrange(p1, p2, nrow = 1); p12
concept_pairs <- as.data.frame(t(combn(unique(usdf$concept), 2))) %>% rename(concept1 = V1, concept2 = V2)
color_pairs <- as.data.frame(t(combn(unique(mgdf$color), 2))) %>% rename(color1 = V1, color2 = V2)
# Aggregated data (x = average rating for each color of each concept)
usdf_agg <- usdf %>% group_by(concept, color) %>% summarise(xbar = mean(rating), sd_sample = sd(rating), .groups = 'drop')
a_us <- coef(getFitSd(usdf_agg)) # alpha a_us = 1.384426
# Plotting the data points, and fitted curve
plot(usdf_agg$xbar, usdf_agg$sd_sample, main = "Fit for model s = a * xbar * (1 - xbar)",
xlab = "Mean (xbar)", ylab = "Standard Deviation (s)", pch = 16)
curve(coef(getFitSd(usdf_agg)) * x * (1 - x), add = TRUE, col = "orange", lwd = 2)
a_us2 <- coef(getFitSd2(usdf_agg)) # alpha a = 0.37, beta b = 0.32
plot(usdf_agg$xbar, usdf_agg$sd_sample, main = "Fit for model s = a * xbar^b",
xlab = "Mean (xbar)", ylab = "Standard Deviation (s)", pch = 16)
curve(coef(getFitSd2(usdf_agg))[1] * x^coef(getFitSd2(usdf_agg))[2], add = TRUE, col = "red", lwd = 2)
# xUs <- getXvalues(usdf_agg, concept_pairs, color_pairs, a_us) %>% mutate(deltaX = (xbar1 + xbar4) - (xbar2 + xbar3))
xUs2 <- getXvalues_opt(usdf_agg, concept_pairs, color_pairs, a_us) %>% mutate(deltaX = (xbar1 + xbar4) - (xbar2 + xbar3))
deltaS_us <- getDeltaS(xUs2) %>% select(concept1, concept2, color1, color2, deltaS_sample, deltaS_fit)
# mean(deltaS_us$deltaS_sample - deltaS_us$deltaS_fit) ~= -0.007, i.e. the fitted S is correct
```
mgdf_agg <- mgdf %>% group_by(concept, color) %>% summarise(xbar = mean(rating), sd_sample = sd(rating), .groups = 'drop')
a_mg <- coef(getFitSd(mgdf_agg)) # a = 1.536
# Plotting the data points, and fitted curve
plot(mgdf_agg$xbar, mgdf_agg$sd_sample, main = "MDG data: Fit for the Function s = a * xbar * (1 - xbar)",
xlab = "Mean (xbar)", ylab = "Standard Deviation (s)", pch = 16)
curve(coef(getFitSd(mgdf_agg)) * x * (1 - x), add = TRUE, col = "orange", lwd = 2)
a_mg2 <- coef(getFitSd2(mgdf_agg))
plot(mgdf_agg$xbar, mgdf_agg$sd_sample, main = "Fit for model s = a * xbar^b",
xlab = "Mean (xbar)", ylab = "Standard Deviation (s)", pch = 16)
curve(coef(getFitSd2(mgdf_agg))[1] * x^coef(getFitSd2(mgdf_agg))[2], add = TRUE, col = "red", lwd = 2)
# xMg <- getXvalues(mgdf_agg, concept_pairs, color_pairs, a_mg) %>% mutate(deltaX = (xbar1 + xbar4) - (xbar2 + xbar3))
xMg2 <- getXvalues_opt(mgdf_agg, concept_pairs, color_pairs, a_mg) %>% mutate(deltaX = (xbar1 + xbar4) - (xbar2 + xbar3))
deltaS_mg <- getDeltaS(xMg2) %>% select(concept1, concept2, color1, color2, deltaS_sample, deltaS_fit)
write_csv(deltaS_mg, "output/mg-deltaD.csv")
write_csv(deltaS_mg, "output/mg-deltaS.csv")
write_csv(deltaS_us, "output/us-deltaS.csv")
head(deltaS_mg, 10)
deltaS_mg_x <- deltaS_mg %>% filter(concept1 %in% c("sick"), concept2 %in% c("tree"))
View(deltaS_mg_x)
deltaS_mg_x <- deltaS_mg %>% filter(concept1 %in% c("sick"), concept2 %in% c("tree"), color1 %in% c("A1"))
deltaS_mg_x <- deltaS_mg %>% filter(concept1 %in% c("sick"), concept2 %in% c("tree"), color1 %in% c("A1"), color2 %in% c("A2"))
deltaS_mg_x <- deltaS_mg %>% filter(concept1 %in% c("sick"), concept2 %in% c("tree"), color1 %in% c("A1"))
deltaS_mg_x <- deltaS_mg %>% filter(concept1 %in% c("tree"), concept2 %in% c("sick"), color1 %in% c("A1"))
DG
deltaS_mg_x <- deltaS_mg %>% filter(concept1 %in% c("tree"), concept2 %in% c("sick"), color1 %in% c("DG"))
deltaS_mg_x <- deltaS_mg %>% filter(concept1 %in% c("sick"), concept2 %in% c("tree"), color1 %in% c("A1"))
a_us <- coef(getFitSd(usdf_agg)) # alpha a_us = 1.384426
# Plotting the data points, and fitted curve
plot(usdf_agg$xbar, usdf_agg$sd_sample, main = "Fit for model s = a * xbar * (1 - xbar)",
xlab = "Mean (xbar)", ylab = "Standard Deviation (s)", pch = 16)
curve(coef(getFitSd(usdf_agg)) * x * (1 - x), add = TRUE, col = "orange", lwd = 2)
View(xMg2)
